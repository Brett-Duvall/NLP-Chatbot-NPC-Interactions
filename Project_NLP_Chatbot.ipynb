{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "615c5923-e734-40fd-a8c6-53770ae3aa4b",
   "metadata": {},
   "source": [
    "## Chatbot for use with NPCs (Non Player Characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6f2a74-a0f5-4e41-ace6-3de85953111b",
   "metadata": {},
   "source": [
    "### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78842736-f196-43a8-b7e6-b7d118e59efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211b7c89-7ba7-4373-a8df-c5d0bb30ef12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24170b8-23a2-409c-92a0-e2e7224989fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install num2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70797a71-7066-434a-9182-a9be53a296a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install faster-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404dfd77-2651-4e73-8a70-73bd2b4f0b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install piper-tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2af9641-ed92-4d81-bf9b-903d3a8591a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b17526-4c7a-47d3-a07a-e7eb9d216c75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install nbconvert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf13525b-7200-4f06-9971-76eab7155623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\brett\\anaconda3\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\brett\\anaconda3\\lib\\site-packages (0.23.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\brett\\anaconda3\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\brett\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\brett\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\brett\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\brett\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\brett\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\brett\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\brett\\anaconda3\\lib\\site-packages (from torch) (80.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\brett\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\brett\\anaconda3\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\brett\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\brett\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0adcecd5-5309-4e43-9639-f79655438ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01f59ebe-5490-446c-ad95-40b27b71f69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/nightly/cu129\n",
      "Requirement already satisfied: torch in c:\\users\\brett\\anaconda3\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\brett\\anaconda3\\lib\\site-packages (0.23.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\brett\\anaconda3\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\brett\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\brett\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\brett\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\brett\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\brett\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\brett\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\brett\\anaconda3\\lib\\site-packages (from torch) (78.1.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\brett\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\brett\\anaconda3\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\brett\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\brett\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu129"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "92f28f5d-fc5d-46a8-bc4e-d7b4f8d019e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/nightly/cu129\n",
      "Requirement already satisfied: torch in c:\\users\\brett\\anaconda3\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\brett\\anaconda3\\lib\\site-packages (0.23.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\brett\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\brett\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\brett\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\brett\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\brett\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\brett\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\brett\\anaconda3\\lib\\site-packages (from torch) (78.1.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\brett\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\brett\\anaconda3\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\brett\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\brett\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --pre torch torchvision --index-url https://download.pytorch.org/whl/nightly/cu129"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44f32db2-ed90-4bc7-9ada-b3f1b93db370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96a0c310-1bbc-4f82-850a-cd7b9923c481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cpu\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70f4091c-71ca-4f00-a419-e65459850d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0be93de-f109-471f-860b-25853a48f229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\n",
      "Version: 2.8.0\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3-Clause\n",
      "Location: C:\\Users\\Brett\\anaconda3\\Lib\\site-packages\n",
      "Requires: filelock, fsspec, jinja2, networkx, setuptools, sympy, typing-extensions\n",
      "Required-by: accelerate, torchaudio, torchvision, ultralytics, ultralytics-thop\n"
     ]
    }
   ],
   "source": [
    "!pip show torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7b9e5a8-2df1-487e-8d89-846e3dab91a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_arch_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e926c9bf-37a1-47a1-98a1-0dd30a97b192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "828d263a-b1e8-49bd-9efc-21f78f3acb2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "from scipy.io import wavfile\n",
    "import os\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "import pyttsx3\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import gc\n",
    "import random\n",
    "from num2words import num2words\n",
    "from faster_whisper import WhisperModel\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c7ea65-a3d1-4423-b2c7-5441375bed19",
   "metadata": {},
   "source": [
    "### tokens for using LLMs at hugging_face and openrouter.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2a423cc-a0af-4e9f-979a-71d9949ed4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is where tokens are stored for LLM use\n",
    "HUGGINGFACE_TOKEN = \"insert_your_token_here\"\n",
    "OPENROUTER_TOKEN = \"insert_your_token_here\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051d69cb-dbc6-4127-8df8-c1c10c21ba09",
   "metadata": {},
   "source": [
    "### creating functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16536aba-e269-4c5c-b1fa-b631c44eea97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert any numbers to their written equivalent\n",
    "def convert_numbers_to_words(text):\n",
    "    def replace_number(match):\n",
    "        num = int(match.group())\n",
    "        return num2words(num, to = 'currency')\n",
    "    return re.sub(r'\\b\\d+\\b', replace_number, text)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fc53934-8ae0-497a-bddb-e8c9d12c4763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize by pauses\n",
    "def split_text_with_pauses(text):\n",
    "    text = ''.join(i for i in text if not i.isdigit())\n",
    "    chunks = re.split(r'[^\\w\\s]', text)\n",
    "    chunks = [chunck.strip() for chunck in chunks if chunk.strip()]\n",
    "    result = []\n",
    "    for chunk in chunks:\n",
    "        result.append(chunk)\n",
    "        result.append(\"pause\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e2e40e1-a128-4f76-88a5-c74fd6063158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize\n",
    "def chunk_into_segments(str_lst, words_per_segment = 5):\n",
    "    adjusted_str_lst = []\n",
    "    for text in str_lst:\n",
    "        if len(text.split(' ')) <= words_per_segment:\n",
    "            adjusted_str_lst.append(text)\n",
    "        else:\n",
    "            tmp_triplet = \"\"\n",
    "            triplet_counter = 0\n",
    "            word_lst = text.split(' ')\n",
    "            total_words = len(word_lst)\n",
    "            for word_idx_start in range(0, totals_words, words_per_segment):\n",
    "                word_idx_end = word_idx_start + words_per_segment\n",
    "                if word_idx_end < totals_words:\n",
    "                    segment = \" \".join(word_lst[word_idx_start:word_idx_end])\n",
    "                else:\n",
    "                    segment = \" \".join(word_lst[word_idx_start:])\n",
    "                adjusted_str_lst.append(segment)\n",
    "    return adjusted_str_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189c0d61-45e5-46da-b363-e979212dec1a",
   "metadata": {},
   "source": [
    "# Text to Speech Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f92821d-28c0-4127-b77d-465f15656089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text to speech engine\n",
    "def setup_engine(language=\"english\"):\n",
    "    \n",
    "    engine = pyttsx3.init()  \n",
    "    voices = engine.getProperty(\"voices\")\n",
    "    available_voices = [voice_name.id for voice_name in engine.getProperty(\"voices\")]\n",
    "    selected_voice = available_voices[available_voices.index(language)]\n",
    "    engine.setProperty('voice', selected_voice)\n",
    "    engine.setProperty('rate', 120)\n",
    "    engine.setProperty('volume', 0.8)\n",
    "    engine.setProperty('pitch', 130)\n",
    "    return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed874b76-14e4-41bf-82fc-a6eba3b762ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  save text and audio\n",
    "def text_to_speech(history):  \n",
    "    if history == []:\n",
    "        return \"\", tuple([22050, np.array([0])])\n",
    "    text_input = history[-1][1]\n",
    "    \n",
    "    print(f\">>>'{text_input}'...\")\n",
    "    \n",
    "    language=\"english\"\n",
    "    if os.path.exists('final_audio.wav'):\n",
    "        os.remove('final_audio.wav')\n",
    "    get_text_to_speech_model = setup_engine(language)\n",
    "    text_with_numbers_to_str = convert_numbers_to_words(text_input)\n",
    "    text_with_pauses = split_text_with_pauses(text_with_numbers_to_str)\n",
    "    text_with_pauses_adjusted = chunk_into_segments(text_with_pauses)\n",
    "    print(f\">>> Post processed to: {text_with_pauses_adjusted}\")\n",
    "    final_audio = []\n",
    "    for text_segment in text_with_pauses_adjusted:\n",
    "        print(text_segment)\n",
    "        if text_segment==\"pause\":\n",
    "            get_text_to_speech_model.save_to_file('.', 'tmp.wav')\n",
    "        else:\n",
    "            get_text_to_speech_model.save_to_file(text_segment, 'tmp.wav')\n",
    "        get_text_to_speech_model.runAndWait() \n",
    "        sr, data = wavfile.read('tmp.wav')\n",
    "        final_audio.append(data)\n",
    "        try:\n",
    "            os.remove(\"tmp.wav\")\n",
    "        except:\n",
    "            pass\n",
    "    final_audio = np.concatenate(final_audio).astype(np.int16)\n",
    "    \n",
    "    print(final_audio.shape, final_audio.shape)\n",
    "    return text_input, tuple([22050, final_audio])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a03488b0-fef2-4c45-8d8f-5a9045092672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data sent to LLM\n",
    "def generate_response(user_input, audio_input, history):\n",
    "    if audio_input:\n",
    "        segments, _ = speech_to_text.transcribe(audio_input)\n",
    "        text_input = ' '.join([segment.text for segment in segments])\n",
    "    else:\n",
    "        text_input = user_input\n",
    "    if text_input == \"\":\n",
    "        response = random.choice([[\"I couldn't read that, please try again.\"], [\"What did you mean?\"], [\"I don't see anything.\"], [\"Please type something.\"]])\n",
    "        history.append((text_input, response))\n",
    "        return history, response, None, \"\", None\n",
    "    print(\"######################################################################\")\n",
    "    print(f\">>> Generating response to: {text_input}\")\n",
    "    print(\"######################################################################\")\n",
    "    # Giving the LLM user and system role information\n",
    "    messages = [ \n",
    "        {\"role\": \"user\", \"content\": text_input},\n",
    "        {\"role\": \"system\", \"content\": \"Make sure to talk with short, funny, medieval tone\"}\n",
    "    ]\n",
    "    prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    outputs = pipe(prompt, max_new_tokens=256) # 512 do_sample=True, temperature=0.7, top_k=50, top_p=0.95, repetition_penalty=1.2\n",
    "    generated_text = outputs[0][\"generated_text\"]\n",
    "    response = generated_text[len(prompt):].strip()  # strips the prompt from the response\n",
    "    response = ' '.join(generated_text.split('<|assistant|>')[1:])\n",
    "    if history is None: # create new history list if none existed\n",
    "        history = []\n",
    "    history.append((text_input, response)) # add the text input and response to the history list of dictionaries\n",
    "    return history, response, None, \"\", None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9d9b8a8-a115-40cc-bea1-47a12358bfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whisper runs on a single CPU core\n",
    "speech_to_text = WhisperModel(\"small\", device=\"cpu\", compute_type=\"int8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3449fce-5f84-4530-8713-f5bc224cd439",
   "metadata": {},
   "source": [
    "# Choose LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "697cba9d-92ce-4fe8-8c98-314e61e51df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb5527efe8514afda1d9500454e82f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n",
      "C:\\Users\\Brett\\anaconda3\\Lib\\site-packages\\torch\\cuda\\__init__.py:235: UserWarning: \n",
      "NVIDIA GeForce RTX 5070 Ti with CUDA capability sm_120 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_50 sm_60 sm_61 sm_70 sm_75 sm_80 sm_86 sm_90.\n",
      "If you want to use the NVIDIA GeForce RTX 5070 Ti GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# gemma 2 9b is a free google LLM\n",
    "pipe = pipeline(\"text-generation\", model=\"google/gemma-2-9b-it\",\n",
    "                model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "                device=\"cuda\", token=HUGGINGFACE_TOKEN) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fae4efa-8e2b-490b-a72e-34745a37e2a3",
   "metadata": {},
   "source": [
    "# Create User Interface for Testing Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf802539-2e92-467c-a11c-2b0f0cc13ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradio window\n",
    "def NPC_chat():\n",
    "    \n",
    "    def terminate(): # Close Gradio window\n",
    "        block.close()  \n",
    "        exit()\n",
    "\n",
    "    with gr.Blocks() as block:\n",
    "        gr.HTML(\n",
    "            f\"\"\"\n",
    "            <h1 style='text-align: center;'> NPC Conversations </h1>\n",
    "            <h3 style='text-align: center;'> Ask a question and you might receive an answer worth your time...</h3>\n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "        chat_history = gr.Chatbot(label=\"Chat History\", type='messages')  \n",
    "\n",
    "        with gr.Group():\n",
    "            with gr.Row():\n",
    "                audio_out = gr.Audio(label=\"Spoken Answer\", streaming=True, autoplay=True)\n",
    "                answer = gr.Textbox(label=\"Answer\")\n",
    "                state = gr.State()\n",
    "            with gr.Row():\n",
    "                # typing input\n",
    "                user_input = gr.Textbox(label=\"Message (press Enter to send):\", placeholder=\"Type your question here...\", elem_id=\"user_input\")\n",
    "                # audio input\n",
    "                audio_in = gr.Audio(label=\"Speak (press stop when finished):\", sources=\"microphone\", type=\"filepath\", elem_id=\"audio_in\")\n",
    "                \n",
    "            with gr.Row():\n",
    "                gr.Markdown(\"\")\n",
    "            with gr.Accordion(\"Stop NPC Chat\", open=False):\n",
    "                \n",
    "                terminate_button = gr.Button(\"STOP\", elem_id=\"terminate_button\")  \n",
    "\n",
    "\n",
    "        # Textbox input\n",
    "        user_input.submit(generate_response, inputs=[user_input, audio_in, state], outputs=[state, answer, audio_out, user_input, audio_in])\\\n",
    "            .then(fn=text_to_speech, inputs=state, outputs=[answer, audio_out])\\\n",
    "            .then(lambda hist: hist, inputs=state, outputs=chat_history)\n",
    "        # Audio input \n",
    "        audio_in.stop_recording(generate_response, inputs=[user_input, audio_in, state], outputs=[state, answer, audio_out, user_input, audio_in])\\\n",
    "            .then(fn=text_to_speech, inputs=state, outputs=[answer, audio_out])\\\n",
    "            .then(lambda hist: hist, inputs=state, outputs=chat_history)\n",
    "        \n",
    "        terminate_button.click(terminate)  \n",
    "\n",
    "\n",
    "    block.css = \"\"\"\n",
    "        #user_input, #audio_in {\n",
    "            height: 200px;  /* Set height for user input, audio input, and button (button excluded) */\n",
    "        }\n",
    "        .gradio-container {\n",
    "            display: flex;\n",
    "            flex-direction: column;\n",
    "            align-items: center;\n",
    "        }\n",
    "        .gradio-row {\n",
    "            width: 100%;\n",
    "            justify-content: center;\n",
    "            align-items: center;\n",
    "            margin-bottom: 15px;\n",
    "        }\n",
    "    \"\"\"\n",
    "\n",
    "    block.launch(server_name=\"0.0.0.0\", share=False) # turning share off ATM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2948bd12-3a2a-40e9-bce1-a01faf61ca51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://0.0.0.0:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://localhost:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NPC_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a85c3d8-19cc-4c3a-bcaa-4e36292e0b84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
